  <p>
Correlation and regression are used in statistical analysis to determine the strength of the
relationship between two variables. For example, variables such as these may be correlated: 
<ul>
  <li>
    A person's age vs. height 
  </li>
  <li>
    Hour's studied for a test vs. test score 
  </li>
  <li>
    Speed vs. time it takes to travel ten miles 
  </li>
</ul>
  </p>
  <p>
Correlation is used to determine the strength as well as the direction of the relationship
between the variables. Two variables are positively correlated if as one variable increases, the
other also increases. Negative correlation is when one variable increases but the other
decreases. 
<a href="{{ '/activities/Regression' | relative_url }}">Linear Regression</a> is used to find the line of best-fit, meaning the line about which the data points are
scattered. 
<a href="{{ '/discussions/BivariateDataRelations' | relative_url }}">Positive and negative correlations</a> correspond to the 
<a href="{{ '/activities/SlopeSlider' | relative_url }}">slope</a> of the best-fit line. The 
<a href="{{ '/discussions/CorrelationCoefficients' | relative_url }}">correlation coefficient</a> is a measure of the strength of the relationship. 
  </p>
  <p>
Multiple regressions are used when trying to determine a good indicator for a random variable.
For example, if you were looking to buy a new car, you could use the price of the car as your
dependant variable. Then you could test its correlation to &quot;predictor&quot; variables such
as horsepower, gas efficiency, resale value, crash safety rating, etc. After doing the analysis,
you might find that a car&apos;s crash safety rating is a better indicator of the overall price
of the car than how many seats it has. You may also discover certain cars that should be priced
more or less given its characteristics, thus being able to identify the best car for the price. 
  </p>
  

